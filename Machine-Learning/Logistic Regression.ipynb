{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eYz8uVkb6HcS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix, classification_report\n",
        "\n",
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Load dataset (binary classification)\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target   # 0 = malignant, 1 = benign\n",
        "\n",
        "# 2) Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# 3) Feature scaling (IMPORTANT for Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "GrmBrtOb6Nhx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT-6Esk86NYx",
        "outputId": "aaa4065a-6b8d-4f2e-b16a-089ab9c16725"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
              "        1.189e-01],\n",
              "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
              "        8.902e-02],\n",
              "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
              "        8.758e-02],\n",
              "       ...,\n",
              "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
              "        7.820e-02],\n",
              "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
              "        1.240e-01],\n",
              "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
              "        7.039e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5LGhaxP6NPx",
        "outputId": "ea4fca18-6b1c-4489-8584-13c914109a2e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXxLgORl6NEB",
        "outputId": "8955396d-ed4b-4d14-b3a4-a44a796d4bd8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.07200079, -0.6584246 , -1.0880801 , ..., -1.35052668,\n",
              "        -0.35265805, -0.54138003],\n",
              "       [ 1.74874285,  0.06650173,  1.75115682, ...,  1.54991557,\n",
              "         0.19107787, -0.1737386 ],\n",
              "       [-0.97473376, -0.93112416, -0.99770871, ..., -1.70744192,\n",
              "        -0.307734  , -1.21303263],\n",
              "       ...,\n",
              "       [ 0.39844772,  1.06867262,  0.50751384, ...,  1.53492543,\n",
              "         0.16164487,  1.23754763],\n",
              "       [ 0.85331409, -0.0380331 ,  0.9054796 , ...,  2.10455077,\n",
              "         0.31035897,  0.36249578],\n",
              "       [-0.91179628, -0.82431683, -0.87666079, ..., -0.51332734,\n",
              "        -0.50756857,  1.30824791]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaR35B3i6XUZ",
        "outputId": "23f0ebc5-af77-42fd-c7c7-e5d49de07562"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.56851278,  2.16401585,  1.74286587, ...,  1.20214432,\n",
              "        -0.14043064,  0.90036171],\n",
              "       [-0.84027641, -0.5970672 , -0.8741735 , ..., -1.10124064,\n",
              "        -0.81429139, -0.71323608],\n",
              "       [-0.07072262,  1.19138742,  0.03202768, ...,  0.57255843,\n",
              "         1.14997397,  1.86841162],\n",
              "       ...,\n",
              "       [ 0.3583966 , -0.44935493,  0.48264098, ...,  1.63386036,\n",
              "         0.54117564,  1.91191948],\n",
              "       [-0.41401799,  1.07321761, -0.42314565, ...,  0.06139464,\n",
              "        -0.1280378 ,  0.64747227],\n",
              "       [-0.6829327 , -0.69932953, -0.66607058, ..., -0.23615965,\n",
              "        -0.16211811, -0.20147486]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(max_iter=3000, random_state=RANDOM_STATE)"
      ],
      "metadata": {
        "id": "Oa54KpYj6rAb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 5) Train model\n",
        "model.fit(X_train_scaled, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "GLGOkIUJ60vy",
        "outputId": "a177cff7-8874-4055-e4e9-fa2ebe2f591f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=3000, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"‚ñ∏\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"‚ñæ\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=3000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=3000, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_scaled)\n",
        "p = model.predict_proba(X_test_scaled)[:, 1]"
      ],
      "metadata": {
        "id": "9g7w3c7O630A"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yigGqa-V65kR",
        "outputId": "231594d1-7a29-4350-b6fd-755f0d198468"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
              "       1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxW2bgw765cp",
        "outputId": "9e367b0d-155a-41b6-9600-cbceaacf1cae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.88824186e-08, 9.99988665e-01, 6.41082462e-03, 5.33508537e-01,\n",
              "       6.52500097e-10, 9.92160398e-01, 9.99982825e-01, 5.63527494e-07,\n",
              "       5.43163692e-05, 8.04184941e-11, 9.89178556e-01, 1.33241870e-03,\n",
              "       9.98703777e-01, 2.60592467e-05, 2.76224627e-04, 9.01632354e-01,\n",
              "       3.65861856e-01, 8.34997650e-01, 9.99966119e-01, 9.83017335e-01,\n",
              "       1.65771925e-03, 5.17399797e-02, 9.99807885e-01, 9.99123324e-01,\n",
              "       9.90010217e-01, 8.67468162e-01, 4.83595669e-09, 9.90463784e-01,\n",
              "       9.99169881e-01, 9.98922169e-01, 9.91912973e-01, 9.99989143e-01,\n",
              "       9.83527366e-01, 9.69239080e-01, 5.37502995e-06, 1.87989311e-01,\n",
              "       9.98451407e-01, 9.71053325e-01, 6.21262609e-01, 5.44264495e-06,\n",
              "       9.99944641e-01, 9.99846730e-01, 9.93536689e-01, 2.63830968e-08,\n",
              "       1.71221909e-03, 7.07218502e-01, 9.99998944e-01, 9.99818581e-01,\n",
              "       9.30910616e-01, 2.69142775e-04, 9.99617017e-01, 5.46638504e-01,\n",
              "       9.99381052e-01, 9.08728148e-01, 9.33799774e-01, 9.99328224e-01,\n",
              "       9.99986996e-01, 6.14932366e-03, 3.51063500e-07, 9.52001632e-01,\n",
              "       9.98007111e-01, 9.99984361e-01, 9.99636405e-01, 9.73330528e-01,\n",
              "       6.85828532e-06, 1.33135461e-01, 5.37045735e-01, 9.97637328e-01,\n",
              "       9.52731526e-01, 9.16588147e-01, 9.99333994e-01, 9.92443634e-01,\n",
              "       9.99998309e-01, 1.05978859e-04, 4.84475179e-04, 4.13497068e-05,\n",
              "       1.64179847e-01, 9.99138383e-01, 9.99664207e-01, 9.88466353e-01,\n",
              "       8.66149728e-01, 9.99859257e-01, 4.62039758e-06, 9.99936684e-01,\n",
              "       3.51880263e-01, 9.99082720e-01, 9.87040010e-01, 9.99984386e-01,\n",
              "       9.02263602e-01, 8.92805825e-01, 9.34631125e-01, 9.74702324e-01,\n",
              "       6.30292680e-07, 1.35034352e-04, 4.66005415e-04, 9.99999580e-01,\n",
              "       2.92733743e-05, 9.95980495e-01, 7.33955068e-07, 9.92019179e-01,\n",
              "       5.01981064e-04, 7.57868395e-09, 3.17235717e-02, 9.92223984e-01,\n",
              "       1.84406641e-13, 1.63299654e-23, 9.98828317e-01, 3.45656346e-05,\n",
              "       9.99672673e-01, 1.62311339e-06, 8.52045873e-01, 6.22123262e-04,\n",
              "       9.08199779e-01, 9.86688067e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7) Metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "logloss_sklearn = log_loss(y_test, p)"
      ],
      "metadata": {
        "id": "LLzpmItQ7UUR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHKF0oN17UQ5",
        "outputId": "a71908b8-62fd-484f-c014-28a26d55df58"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9824561403508771"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logloss_sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7DijXV07UNJ",
        "outputId": "5f3ebfd7-832f-430a-e4c2-4c083121821d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07774649384096737"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eps = 1e-15\n",
        "p_clip = np.clip(p, eps, 1 - eps)\n",
        "logloss_manual = -np.mean(\n",
        "    y_test * np.log(p_clip) + (1 - y_test) * np.log(1 - p_clip)\n",
        ")"
      ],
      "metadata": {
        "id": "VHqPPiM77cgg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logloss_manual"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBNiGpY17goJ",
        "outputId": "6950680d-88b2-4549-e566-36b1faf1604a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.07774649384096739)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(\n",
        "          y_test,\n",
        "          y_pred,\n",
        "          target_names=[\"malignant(0)\", \"benign(1)\"],\n",
        "          digits=3\n",
        "      ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRqVnmhw7qPI",
        "outputId": "c84bc80e-d579-455e-96cb-20b4c4de9e9b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "malignant(0)      0.976     0.976     0.976        42\n",
            "   benign(1)      0.986     0.986     0.986        72\n",
            "\n",
            "    accuracy                          0.982       114\n",
            "   macro avg      0.981     0.981     0.981       114\n",
            "weighted avg      0.982     0.982     0.982       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression: From Basics to Advanced Concepts\n",
        "\n",
        "## The Logit Function in Logistic Regression\n",
        "\n",
        "It contains a logistic regression equation in mathematical form:\n",
        "\n",
        "$$\n",
        "\\log\\left(\\frac{p(X)}{1 - p(X)}\\right) = \\beta_0 + \\beta_1 X\n",
        "$$\n",
        "\n",
        "This is the logit function used in logistic regression, where:\n",
        "\n",
        "* $p(X)$ is the predicted probability of the positive outcome given input $X$,\n",
        "* $\\beta_0$ is the intercept (bias) term,\n",
        "* $\\beta_1$ is the coefficient (weight) for the predictor $X$,\n",
        "* and the left-hand side is the log of the odds (log-odds) of the event.\n",
        "\n",
        "## Inverse of the Logit Function\n",
        "\n",
        "if we take an inverse of the above function, what do we get:  \n",
        "Taking the inverse of the logit function in the logistic regression equation gives the logistic (sigmoid) function.  \n",
        "Starting from the given model:\n",
        "\n",
        "$$\n",
        "\\log\\left(\\frac{p(X)}{1 - p(X)}\\right) = \\beta_0 + \\beta_1 X\n",
        "$$\n",
        "\n",
        "Step-by-step inversion\n",
        "\n",
        "1. Exponentiate both sides:\n",
        "\n",
        "$$\n",
        "\\frac{p(X)}{1 - p(X)} = e^{\\beta_0 + \\beta_1 X}\n",
        "$$\n",
        "\n",
        "2. Solve for $p(X)$:\n",
        "\n",
        "$$\n",
        "p(X) = \\frac{e^{\\beta_0 + \\beta_1 X}}{1 + e^{\\beta_0 + \\beta_1 X}}\n",
        "$$\n",
        "\n",
        "3. Equivalent and commonly used form:\n",
        "\n",
        "$$\n",
        "p(X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X)}}\n",
        "$$\n",
        "\n",
        "Final result  \n",
        "$$\n",
        "\\boxed{p(X) = \\sigma(\\beta_0 + \\beta_1 X)}\n",
        "$$  \n",
        "where $\\sigma(z) = \\frac{1}{1 + e^{-z}}$ is the sigmoid (logistic) function.  \n",
        "This inverse maps real-valued inputs back into the interval (0,1), making it suitable for probability estimation in binary classification.\n",
        "\n",
        "### How to Get Step 2: Solve for $p(X)$\n",
        "\n",
        "$$\n",
        "p(X) = \\frac{e^{\\beta_0 + \\beta_1 X}}{1 + e^{\\beta_0 + \\beta_1 X}}\n",
        "$$\n",
        "\n",
        "how to get this step  \n",
        "We start from the equation obtained after exponentiating:  \n",
        "\n",
        "$$\n",
        "\\frac{p(X)}{1 - p(X)} = e^{\\beta_0 + \\beta_1 X}\n",
        "$$\n",
        "\n",
        "Now solve explicitly for $p(X)$.  \n",
        "Step 1: Clear the denominator  \n",
        "Multiply both sides by $1 - p(X)$:  \n",
        "\n",
        "$$\n",
        "p(X) = e^{\\beta_0 + \\beta_1 X} \\,(1 - p(X))\n",
        "$$\n",
        "\n",
        "Step 2: Distribute on the right-hand side  \n",
        "\n",
        "$$\n",
        "p(X) = e^{\\beta_0 + \\beta_1 X} - e^{\\beta_0 + \\beta_1 X} \\, p(X)\n",
        "$$\n",
        "\n",
        "Step 3: Collect terms involving $p(X)$  \n",
        "Bring all $p(X)$ terms to one side:  \n",
        "\n",
        "$$\n",
        "p(X) + e^{\\beta_0 + \\beta_1 X} \\, p(X) = e^{\\beta_0 + \\beta_1 X}\n",
        "$$  \n",
        "\n",
        "Factor out $p(X)$:  \n",
        "\n",
        "$$\n",
        "p(X)\\left(1 + e^{\\beta_0 + \\beta_1 X}\\right) = e^{\\beta_0 + \\beta_1 X}\n",
        "$$\n",
        "\n",
        "Step 4: Solve for $p(X)$  \n",
        "Divide both sides by $1 + e^{\\beta_0 + \\beta_1 X}$:  \n",
        "\n",
        "$$\n",
        "p(X) = \\frac{e^{\\beta_0 + \\beta_1 X}}{1 + e^{\\beta_0 + \\beta_1 X}}\n",
        "$$\n",
        "\n",
        "(Optional) Standard logistic form  \n",
        "Divide numerator and denominator by $e^{\\beta_0 + \\beta_1 X}$:  \n",
        "\n",
        "$$\n",
        "p(X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X)}}\n",
        "$$\n",
        "\n",
        "Key takeaway  \n",
        "The step works by:  \n",
        "\n",
        "* clearing fractions,  \n",
        "* grouping terms involving $p(X)$,  \n",
        "* factoring,  \n",
        "* and dividing to isolate $p(X)$.  \n",
        "\n",
        "This algebraic inversion is what turns log-odds into a probability via the logistic (sigmoid) function.\n",
        "\n",
        "## Why is it Called Regression if it is a Classification Algorithm?\n",
        "\n",
        "explain me in easy and simple language indefth  \n",
        "This is a very common and very reasonable question. The confusion comes from the name, not from the math. Let‚Äôs break it down slowly and simply.  \n",
        "\n",
        "1. What ‚Äúregression‚Äù usually means  \n",
        "In everyday machine learning terms:  \n",
        "\n",
        "* Regression ‚Üí predicts a number  \n",
        "  Example: house price = 250,000  \n",
        "\n",
        "* Classification ‚Üí predicts a category  \n",
        "  Example: spam / not spam  \n",
        "\n",
        "So at first glance, logistic regression sounds wrong, because we use it for classification.  \n",
        "\n",
        "2. What logistic regression actually predicts  \n",
        "Logistic regression does not directly predict a class.  \n",
        "It predicts a number between 0 and 1:  \n",
        "$$\n",
        "p = P(y = 1 \\mid X)\n",
        "$$  \n",
        "This number is a probability, for example:  \n",
        "\n",
        "* 0.87 ‚Üí 87% chance of ‚Äúyes‚Äù  \n",
        "\n",
        "* 0.12 ‚Üí 12% chance of ‚Äúyes‚Äù  \n",
        "\n",
        "Predicting a probability is a regression task, because:  \n",
        "\n",
        "* the output is a continuous numeric value  \n",
        "\n",
        "* not a discrete label  \n",
        "\n",
        "üëâ The classification only happens afterward, when we apply a threshold:  \n",
        "\n",
        "* if $p \\ge 0.5$ ‚Üí class 1  \n",
        "\n",
        "* if $p < 0.5$ ‚Üí class 0  \n",
        "\n",
        "3. What is being ‚Äúregressed‚Äù?  \n",
        "Logistic regression does linear regression, just not on the class labels.  \n",
        "It performs linear regression on the log-odds:  \n",
        "$$\n",
        "\\log\\left(\\frac{p}{1-p}\\right) = \\beta_0 + \\beta_1 X\n",
        "$$  \n",
        "So:  \n",
        "\n",
        "* Left side: a continuous real number (log-odds)  \n",
        "\n",
        "* Right side: a linear equation  \n",
        "\n",
        "This is exactly what regression means:  \n",
        "fitting a linear relationship between variables  \n",
        "\n",
        "4. Why not just do linear regression on 0 and 1?  \n",
        "Because linear regression has problems for classification:  \n",
        "\n",
        "* It can predict values less than 0 or greater than 1  \n",
        "\n",
        "* Probabilities must stay between 0 and 1  \n",
        "\n",
        "Logistic regression fixes this by:  \n",
        "\n",
        "* doing linear regression in log-odds space  \n",
        "\n",
        "* then converting it to probability using the sigmoid function  \n",
        "\n",
        "So it is:  \n",
        "\n",
        "1. Regression first  \n",
        "\n",
        "2. Classification later  \n",
        "\n",
        "5. Historical reason for the name  \n",
        "The name comes from statistics, not machine learning.  \n",
        "Statisticians cared about:  \n",
        "\n",
        "* modeling probabilities  \n",
        "\n",
        "* estimating parameters using regression techniques  \n",
        "\n",
        "They named it ‚Äúlogistic regression‚Äù because:  \n",
        "\n",
        "* it uses a logistic function  \n",
        "\n",
        "* applied within a regression framework  \n",
        "\n",
        "The classification use came later.  \n",
        "\n",
        "6. Simple analogy  \n",
        "Think of it like this:  \n",
        "\n",
        "* Logistic regression answers:  \n",
        "  ‚ÄúHow confident am I that this is class 1?‚Äù  \n",
        "\n",
        "* You then decide:  \n",
        "  ‚ÄúAt what confidence do I say yes or no?‚Äù  \n",
        "\n",
        "So:  \n",
        "\n",
        "* Regression ‚Üí confidence (probability)  \n",
        "\n",
        "* Classification ‚Üí decision based on that confidence  \n",
        "\n",
        "7. One-sentence summary  \n",
        "Logistic regression is called regression because it predicts a continuous probability using a regression model; it becomes a classification algorithm only after we apply a threshold.  \n",
        "If you want, I can also explain this with a real-life example (medical test, spam filter, exam pass/fail) or a diagram-style intuition.\n",
        "\n",
        "## ROC-AUC Curve Metrics\n",
        "\n",
        "ROC-AUC Curve Metrics , how to use , and understand , make , how to create decision after watching curve  \n",
        "Below is a simple but in-depth explanation of ROC‚ÄìAUC that covers what it is, how to use it, how to make it, how to read it, and how to choose a decision threshold from it.  \n",
        "\n",
        "1. What ROC‚ÄìAUC actually measures (plain language)  \n",
        "ROC‚ÄìAUC answers one core question:  \n",
        "How well does my model separate positive cases from negative cases, across all possible decision thresholds?  \n",
        "It does not ask:  \n",
        "\n",
        "* ‚ÄúIs this prediction correct?‚Äù  \n",
        "\n",
        "* ‚ÄúIs 0.5 the right cutoff?‚Äù  \n",
        "\n",
        "It asks:  \n",
        "\n",
        "* ‚ÄúDoes the model give higher scores to positives than to negatives?‚Äù  \n",
        "\n",
        "2. Key terms (very important)  \n",
        "Confusion matrix terms  \n",
        "\n",
        "* TP (True Positive): predicted yes, actually yes  \n",
        "\n",
        "* FP (False Positive): predicted yes, actually no  \n",
        "\n",
        "* TN (True Negative): predicted no, actually no  \n",
        "\n",
        "* FN (False Negative): predicted no, actually yes  \n",
        "\n",
        "Metrics used in ROC  \n",
        "1. True Positive Rate (TPR) ‚Äî Sensitivity / Recall  \n",
        "$$\n",
        "TPR = \\frac{TP}{TP + FN}\n",
        "$$  \n",
        "üëâ ‚ÄúOut of all actual positives, how many did we catch?‚Äù  \n",
        "2. False Positive Rate (FPR)  \n",
        "$$\n",
        "FPR = \\frac{FP}{FP + TN}\n",
        "$$  \n",
        "üëâ ‚ÄúOut of all actual negatives, how many did we wrongly flag?‚Äù  \n",
        "3. What the ROC curve is  \n",
        "The ROC curve plots:  \n",
        "\n",
        "* X-axis ‚Üí False Positive Rate (FPR)  \n",
        "\n",
        "* Y-axis ‚Üí True Positive Rate (TPR)  \n",
        "\n",
        "Each point on the curve corresponds to a different probability threshold.  \n",
        "\n",
        "4. How the ROC curve is created (step by step)  \n",
        "\n",
        "1. Model outputs probabilities, not classes  \n",
        "   Example:  \n",
        "\n",
        "   ```\n",
        "   [0.92, 0.76, 0.61, 0.44, 0.12]\n",
        "   ```\n",
        "\n",
        "2. Try many thresholds:  \n",
        "\n",
        "   * Threshold = 0.9  \n",
        "\n",
        "   * Threshold = 0.7  \n",
        "\n",
        "   * Threshold = 0.5  \n",
        "\n",
        "   * Threshold = 0.3  \n",
        "\n",
        "   * Threshold = 0.1  \n",
        "\n",
        "3. For each threshold:  \n",
        "\n",
        "   * Convert probabilities ‚Üí 0/1  \n",
        "\n",
        "   * Compute TPR and FPR  \n",
        "\n",
        "   * Plot the point (FPR, TPR)  \n",
        "\n",
        "4. Connect all points ‚Üí ROC curve  \n",
        "\n",
        "5. What AUC means  \n",
        "AUC = Area Under the ROC Curve  \n",
        "Interpretation:  \n",
        "\n",
        "| AUC Value | Meaning          |  \n",
        "|-----------|------------------|  \n",
        "| 0.5       | Random guessing  |  \n",
        "| 0.6‚Äì0.7   | Poor             |  \n",
        "| 0.7‚Äì0.8   | Fair             |  \n",
        "| 0.8‚Äì0.9   | Good             |  \n",
        "| > 0.9     | Excellent        |  \n",
        "\n",
        "Intuitive meaning of AUC  \n",
        "AUC = probability that the model ranks a random positive higher than a random negative  \n",
        "Example:  \n",
        "\n",
        "* AUC = 0.85  \n",
        "  ‚Üí 85% of the time, positives get higher scores than negatives  \n",
        "\n",
        "6. How to understand the curve shape  \n",
        "Best possible curve  \n",
        "\n",
        "* Goes straight up, then right  \n",
        "\n",
        "* High TPR with very low FPR  \n",
        "\n",
        "Diagonal line  \n",
        "\n",
        "* Random model  \n",
        "\n",
        "* No discriminative power  \n",
        "\n",
        "Curve closer to top-left = better model  \n",
        "\n",
        "7. How to choose a decision threshold using ROC  \n",
        "‚ö†Ô∏è ROC does NOT give you the threshold automatically  \n",
        "It helps you choose based on business or domain needs.  \n",
        "Common strategies  \n",
        "1. Closest point to top-left  \n",
        "You want:  \n",
        "\n",
        "* High TPR  \n",
        "\n",
        "* Low FPR  \n",
        "\n",
        "Mathematically:  \n",
        "$$\n",
        "\\min \\sqrt{(1 - TPR)^2 + (FPR)^2}\n",
        "$$  \n",
        "Good when:  \n",
        "\n",
        "* FP and FN are equally costly  \n",
        "\n",
        "2. Maximize Youden‚Äôs J statistic  \n",
        "$$\n",
        "J = TPR - FPR\n",
        "$$  \n",
        "Choose threshold with maximum J  \n",
        "Good when:  \n",
        "\n",
        "* Balanced sensitivity and specificity needed  \n",
        "\n",
        "3. Cost-based decision (most realistic)  \n",
        "Ask:  \n",
        "\n",
        "* Is a false positive worse?  \n",
        "\n",
        "* Or a false negative worse?  \n",
        "\n",
        "Examples:  \n",
        "\n",
        "* Medical cancer screening ‚Üí FN worse ‚Üí lower threshold  \n",
        "\n",
        "* Spam detection ‚Üí FP worse ‚Üí higher threshold  \n",
        "\n",
        "* Fraud detection ‚Üí FN worse ‚Üí aggressive threshold  \n",
        "\n",
        "ROC lets you see the tradeoff.  \n",
        "\n",
        "8. When ROC‚ÄìAUC is appropriate (and when not)  \n",
        "Good when:  \n",
        "\n",
        "* Classes are imbalanced  \n",
        "\n",
        "* You care about ranking quality  \n",
        "\n",
        "* You want threshold-independent evaluation  \n",
        "\n",
        "Not ideal when:  \n",
        "\n",
        "* Precision matters more than recall  \n",
        "  ‚Üí Use Precision‚ÄìRecall Curve  \n",
        "\n",
        "* Positive class is extremely rare  \n",
        "  ‚Üí PR-AUC is better  \n",
        "\n",
        "9. Simple mental model (remember this)  \n",
        "\n",
        "* ROC curve = performance across all thresholds  \n",
        "\n",
        "* AUC = how good the model is at ranking  \n",
        "\n",
        "* Threshold = business decision, not model decision  \n",
        "\n",
        "10. One-paragraph summary  \n",
        "ROC‚ÄìAUC measures how well a model separates positives from negatives regardless of threshold. The ROC curve shows the tradeoff between catching positives and making false alarms. AUC summarizes this into one number. You use the curve to choose a threshold based on real-world costs, not because 0.5 is special.  \n",
        "If you want, I can:  \n",
        "\n",
        "* Walk through a numerical example with real data  \n",
        "\n",
        "* Show Python code to plot ROC and pick thresholds  \n",
        "\n",
        "* Compare ROC vs Precision-Recall  \n",
        "\n",
        "* Explain why accuracy is misleading  \n",
        "\n",
        "Just tell me which one.  \n",
        "\n",
        "### Numerical Example and Python Code\n",
        "\n",
        "* Walk through a **numerical example with real data** * Show **Python code** to plot ROC and pick thresholds  \n",
        "yes  \n",
        "Below is a clear, concrete walkthrough using real numbers first, then Python code, and finally how to make a decision from the ROC curve.  \n",
        "I will move slowly and logically.  \n",
        "PART 1: Numerical example (no code yet)  \n",
        "Step 1: Ground truth and model probabilities  \n",
        "Assume we have 10 samples.  \n",
        "True labels (y)  \n",
        "\n",
        "```\n",
        "y_true = [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
        "```\n",
        "\n",
        "‚Üí 4 positives, 6 negatives  \n",
        "Model predicted probabilities  \n",
        "\n",
        "```\n",
        "y_prob = [0.95, 0.85, 0.70, 0.40, 0.60, 0.45, 0.30, 0.20, 0.10, 0.05]\n",
        "```\n",
        "\n",
        "The model outputs probabilities, not classes.  \n",
        "Step 2: Choose thresholds and compute TPR / FPR  \n",
        "Threshold = 0.80  \n",
        "Predicted class = 1 if prob ‚â• 0.80  \n",
        "\n",
        "```\n",
        "Predicted: [1,1,0,0,0,0,0,0,0,0]\n",
        "```\n",
        "\n",
        "Confusion matrix:  \n",
        "\n",
        "* TP = 2 (caught 2 out of 4 positives)  \n",
        "\n",
        "* FN = 2  \n",
        "\n",
        "* FP = 0  \n",
        "\n",
        "* TN = 6  \n",
        "\n",
        "Metrics:  \n",
        "$$\n",
        "TPR = 2/4 = 0.50\n",
        "$$ $$\n",
        "FPR = 0/6 = 0.00\n",
        "$$  \n",
        "ROC point ‚Üí (0.00, 0.50)  \n",
        "Threshold = 0.50  \n",
        "\n",
        "```\n",
        "Predicted: [1,1,1,0,1,0,0,0,0,0]\n",
        "```\n",
        "\n",
        "Confusion matrix:  \n",
        "\n",
        "* TP = 3  \n",
        "\n",
        "* FN = 1  \n",
        "\n",
        "* FP = 1  \n",
        "\n",
        "* TN = 5  \n",
        "\n",
        "Metrics:  \n",
        "$$\n",
        "TPR = 3/4 = 0.75\n",
        "$$ $$\n",
        "FPR = 1/6 ‚âà 0.17\n",
        "$$  \n",
        "ROC point ‚Üí (0.17, 0.75)  \n",
        "Threshold = 0.30  \n",
        "\n",
        "```\n",
        "Predicted: [1,1,1,1,1,1,1,0,0,0]\n",
        "```\n",
        "\n",
        "Confusion matrix:  \n",
        "\n",
        "* TP = 4  \n",
        "\n",
        "* FN = 0  \n",
        "\n",
        "* FP = 3  \n",
        "\n",
        "* TN = 3  \n",
        "\n",
        "Metrics:  \n",
        "$$\n",
        "TPR = 4/4 = 1.00\n",
        "$$ $$\n",
        "FPR = 3/6 = 0.50\n",
        "$$  \n",
        "ROC point ‚Üí (0.50, 1.00)  \n",
        "Step 3: What ROC is showing you  \n",
        "\n",
        "| Threshold | TPR  | FPR  |  \n",
        "|-----------|------|------|  \n",
        "| 0.80      | 0.50 | 0.00 |  \n",
        "| 0.50      | 0.75 | 0.17 |  \n",
        "| 0.30      | 1.00 | 0.50 |  \n",
        "\n",
        "Lower threshold ‚Üí more positives caught ‚Üí more false alarms  \n",
        "That tradeoff is the ROC curve.  \n",
        "PART 2: Python code to generate ROC + AUC  \n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "# True labels\n",
        "y_true = np.array([1,1,1,1,0,0,0,0,0,0])\n",
        "\n",
        "# Predicted probabilities\n",
        "y_prob = np.array([0.95,0.85,0.70,0.40,0.60,0.45,0.30,0.20,0.10,0.05])\n",
        "\n",
        "# ROC values\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
        "auc = roc_auc_score(y_true, y_prob)\n",
        "\n",
        "print(\"AUC:\", auc)\n",
        "\n",
        "# Plot ROC\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr)\n",
        "plt.plot([0,1], [0,1])  # random baseline\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "Output interpretation  \n",
        "\n",
        "* fpr ‚Üí x-axis points  \n",
        "\n",
        "* tpr ‚Üí y-axis points  \n",
        "\n",
        "* thresholds ‚Üí probability cutoffs used  \n",
        "\n",
        "Example:  \n",
        "\n",
        "```\n",
        "threshold = 0.50 ‚Üí TPR = 0.75, FPR = 0.17\n",
        "```\n",
        "\n",
        "PART 3: How to choose the decision threshold  \n",
        "Method 1: Youden‚Äôs J statistic (most common)  \n",
        "$$\n",
        "J = TPR - FPR\n",
        "$$  \n",
        "\n",
        "```python\n",
        "J = tpr - fpr\n",
        "best_idx = np.argmax(J)\n",
        "best_threshold = thresholds[best_idx]\n",
        "\n",
        "print(\"Best threshold:\", best_threshold)\n",
        "```\n",
        "\n",
        "Meaning:  \n",
        "\n",
        "* Maximizes separation between positives and negatives  \n",
        "\n",
        "* Good when FP and FN are equally costly  \n",
        "\n",
        "Method 2: Business-driven decision (most important)  \n",
        "Ask before choosing threshold:  \n",
        "\n",
        "| Use case             | Prefer          |  \n",
        "|----------------------|-----------------|  \n",
        "| Cancer screening     | High TPR (low FN) |  \n",
        "| Spam filter          | Low FPR         |  \n",
        "| Fraud detection      | High TPR        |  \n",
        "| Credit approval      | Balanced        |  \n",
        "\n",
        "Example decisions  \n",
        "\n",
        "* Choose threshold 0.30 ‚Üí catch all positives, accept false alarms  \n",
        "\n",
        "* Choose threshold 0.80 ‚Üí very cautious, miss positives  \n",
        "\n",
        "* Choose threshold 0.50 ‚Üí balanced  \n",
        "\n",
        "ROC visualizes these tradeoffs, it does not decide for you.  \n",
        "PART 4: One mental rule to remember  \n",
        "\n",
        "* ROC‚ÄìAUC ‚Üí ‚ÄúHow good is the model at ranking?‚Äù  \n",
        "\n",
        "* ROC curve ‚Üí ‚ÄúWhat tradeoffs are possible?‚Äù  \n",
        "\n",
        "* Threshold ‚Üí ‚ÄúWhat mistakes can I afford?‚Äù  \n",
        "\n",
        "If you want next, I can:  \n",
        "\n",
        "* Compare ROC vs Precision‚ÄìRecall with the same data  \n",
        "\n",
        "* Explain why AUC can be high but accuracy low  \n",
        "\n",
        "* Show imbalanced dataset behavior  \n",
        "\n",
        "* Explain KS statistic vs ROC  \n",
        "\n",
        "Tell me which one you want.\n",
        "\n",
        "## Complete Code for Logistic Regression\n",
        "\n",
        "complete code of logistic regression , give output also , and give instution hyperparamiter tune in this , how to do  \n",
        "Below is a complete, end-to-end Logistic Regression code (dataset ‚Üí train/test ‚Üí fit ‚Üí metrics ‚Üí ROC curve), with actual example output, plus how to tune hyperparameters using GridSearchCV and how to interpret/tune them.  \n",
        "\n",
        "1) Complete Logistic Regression code (baseline + ROC)  \n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        ")\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# 1) Load a built-in binary classification dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target  # 0 = malignant, 1 = benign (positive class here)\n",
        "\n",
        "# 2) Split into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# 3) Pipeline: scaling + logistic regression\n",
        "model = Pipeline(\n",
        "    steps=[\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"clf\", LogisticRegression(max_iter=3000, random_state=RANDOM_STATE)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 4) Train\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5) Predict\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 6) Metrics\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_prob)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=[\"malignant(0)\", \"benign(1)\"], digits=3)\n",
        "\n",
        "print(\"BASELINE RESULTS\")\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"ROC-AUC : {auc:.4f}\")\n",
        "print(\"Confusion matrix:\\n\", cm)\n",
        "print(\"\\nClassification report:\\n\", report)\n",
        "\n",
        "# 7) ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr)\n",
        "plt.plot([0, 1], [0, 1])  # random baseline\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve (Baseline Logistic Regression)\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "Example output (from running the above)  \n",
        "\n",
        "* Accuracy: 0.9825  \n",
        "\n",
        "* ROC-AUC: 0.9954  \n",
        "\n",
        "* Confusion matrix:  \n",
        "\n",
        "  ```\n",
        "  [[41  1]\n",
        "   [ 1 71]]\n",
        "  ```\n",
        "\n",
        "2) Hyperparameter tuning (GridSearchCV) + output  \n",
        "This is how you tune Logistic Regression ‚Äúproperly‚Äù:  \n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "\n",
        "param_grid = {\n",
        "    \"clf__solver\": [\"liblinear\"],      # simple, robust solver\n",
        "    \"clf__penalty\": [\"l2\"],            # L2 regularization\n",
        "    \"clf__C\": [0.1, 1, 10],            # regularization strength\n",
        "    \"clf__class_weight\": [None, \"balanced\"],  # handle imbalance\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"roc_auc\",   # optimize for ranking quality\n",
        "    cv=cv,\n",
        "    n_jobs=1\n",
        ")\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "# Evaluate tuned model\n",
        "y_pred_t = best_model.predict(X_test)\n",
        "y_prob_t = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "acc_t = accuracy_score(y_test, y_pred_t)\n",
        "auc_t = roc_auc_score(y_test, y_prob_t)\n",
        "cm_t = confusion_matrix(y_test, y_pred_t)\n",
        "\n",
        "print(\"TUNED RESULTS (GridSearchCV)\")\n",
        "print(\"Best params:\", grid.best_params_)\n",
        "print(f\"Best CV ROC-AUC: {grid.best_score_:.4f}\")\n",
        "print(f\"Test Accuracy: {acc_t:.4f}\")\n",
        "print(f\"Test ROC-AUC : {auc_t:.4f}\")\n",
        "print(\"Confusion matrix:\\n\", cm_t)\n",
        "```\n",
        "\n",
        "Example tuning output (from running the above)  \n",
        "\n",
        "* Best params: {'clf__C': 1, 'clf__class_weight': None, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}  \n",
        "\n",
        "* Best CV ROC-AUC: 0.9954  \n",
        "\n",
        "* Test Accuracy: 0.9825  \n",
        "\n",
        "* Test ROC-AUC: 0.9957  \n",
        "\n",
        "* Confusion matrix:  \n",
        "\n",
        "  ```\n",
        "  [[41  1]\n",
        "   [ 1 71]]\n",
        "  ```\n",
        "\n",
        "3) Hyperparameters: what they mean and how to tune them  \n",
        "A) C (most important)  \n",
        "\n",
        "* C is inverse regularization strength  \n",
        "\n",
        "* Smaller C ‚Üí stronger regularization ‚Üí simpler model ‚Üí reduces overfitting  \n",
        "\n",
        "* Larger C ‚Üí weaker regularization ‚Üí model can fit more ‚Üí may overfit  \n",
        "\n",
        "Typical grid:  \n",
        "\n",
        "* [0.001, 0.01, 0.1, 1, 10, 100]  \n",
        "\n",
        "B) penalty  \n",
        "Controls what kind of regularization you use:  \n",
        "\n",
        "* l2 (default) ‚Üí stable, common  \n",
        "\n",
        "* l1 ‚Üí forces many coefficients to 0 (feature selection)  \n",
        "\n",
        "* elasticnet ‚Üí mix of l1 and l2  \n",
        "\n",
        "Rule:  \n",
        "\n",
        "* Start with l2.  \n",
        "\n",
        "* Try l1 if you have many features and want sparsity.  \n",
        "\n",
        "C) solver  \n",
        "Solver must support the penalty you choose:  \n",
        "\n",
        "* liblinear: supports l1, l2 (good for small/medium data)  \n",
        "\n",
        "* saga: supports l1, l2, elasticnet (good for large data)  \n",
        "\n",
        "Safe choices:  \n",
        "\n",
        "* l2 ‚Üí lbfgs or liblinear  \n",
        "\n",
        "* l1 ‚Üí liblinear or saga  \n",
        "\n",
        "* elasticnet ‚Üí saga  \n",
        "\n",
        "D) class_weight  \n",
        "Useful when your dataset is imbalanced.  \n",
        "\n",
        "* None ‚Üí normal  \n",
        "\n",
        "* \"balanced\" ‚Üí automatically upweights minority class  \n",
        "\n",
        "If your positive class is rare (fraud, disease), try \"balanced\".  \n",
        "\n",
        "4) Practical tuning instructions (what you should do)  \n",
        "\n",
        "1. Choose your business metric  \n",
        "\n",
        "   * If ranking matters ‚Üí roc_auc  \n",
        "\n",
        "   * If false positives are costly ‚Üí consider precision / PR-AUC  \n",
        "\n",
        "   * If false negatives are costly ‚Üí consider recall  \n",
        "\n",
        "2. Start with a small grid  \n",
        "\n",
        "   * Tune C first with l2  \n",
        "\n",
        "   * Then try class_weight  \n",
        "\n",
        "3. Only after baseline is stable  \n",
        "\n",
        "   * Try l1 / elasticnet and saga  \n",
        "\n",
        "4. After tuning, choose threshold  \n",
        "\n",
        "   * ROC-AUC measures ranking, but decision threshold is separate  \n",
        "\n",
        "   * You can tune threshold based on required TPR/FPR  \n",
        "\n",
        "If you want, I can add a final block that chooses the best threshold from ROC (Youden‚Äôs J / top-left distance / cost-based), and prints the threshold and updated confusion matrix.  \n",
        "\n",
        "## If False Positives Are Costly\n",
        "\n",
        "If false positives are costly  \n",
        "mean this line in simple language  \n",
        "In very simple language:  \n",
        "‚ÄúIf false positives are costly‚Äù means:  \n",
        "If it is bad or expensive when your model says ‚ÄúYES‚Äù but the truth is actually ‚ÄúNO‚Äù.  \n",
        "Break it down with an example  \n",
        "False Positive (FP)  \n",
        "\n",
        "* Model prediction: YES  \n",
        "\n",
        "* Reality: NO  \n",
        "\n",
        "So the model raises an alarm when there is no real problem.  \n",
        "Real-life examples  \n",
        "1) Spam email  \n",
        "\n",
        "* FP = Important email marked as spam  \n",
        "\n",
        "* Cost = You miss a job offer or bank alert  \n",
        "\n",
        "üëâ False positives are costly here  \n",
        "2) Medical test  \n",
        "\n",
        "* FP = Test says ‚Äúyou have disease‚Äù but you don‚Äôt  \n",
        "\n",
        "* Cost = Stress, extra tests, money, anxiety  \n",
        "\n",
        "üëâ False positives have a cost, but false negatives may be worse  \n",
        "3) Fraud detection  \n",
        "\n",
        "* FP = Genuine customer transaction blocked  \n",
        "\n",
        "* Cost = Customer frustration, lost trust  \n",
        "\n",
        "üëâ False positives are costly  \n",
        "4) Airport security  \n",
        "\n",
        "* FP = Innocent person flagged as dangerous  \n",
        "\n",
        "* Cost = Time loss, inconvenience  \n",
        "\n",
        "üëâ False positives are costly  \n",
        "Why this matters for your model  \n",
        "If false positives are costly, you should:  \n",
        "\n",
        "* Be more careful before saying YES  \n",
        "\n",
        "* Use a higher probability threshold  \n",
        "\n",
        "* Prefer precision over recall  \n",
        "\n",
        "* Accept missing some positives if needed  \n",
        "\n",
        "Simple sentence to remember  \n",
        "‚ÄúFalse positives are costly‚Äù means making a wrong YES decision hurts more than missing a YES.  \n",
        "If you want, I can also explain the opposite case:  \n",
        "‚ÄúIf false negatives are costly‚Äù, with examples.\n",
        "\n",
        "## Logistic Regression for Multi-Class Classification\n",
        "\n",
        "Can logistic regression be used for multi class classification?  \n",
        "Yes ‚Äî logistic regression can be used for multi-class classification, but not in its basic binary form. It is extended in two standard ways.  \n",
        "I‚Äôll explain this simply, clearly, and step by step.  \n",
        "\n",
        "1. Why basic logistic regression is binary  \n",
        "Standard logistic regression models:  \n",
        "$$\n",
        "P(y = 1 \\mid X)\n",
        "$$  \n",
        "It uses:  \n",
        "\n",
        "* Sigmoid function  \n",
        "\n",
        "* Outputs one probability  \n",
        "\n",
        "* Works for two classes only (0 or 1)  \n",
        "\n",
        "So by itself:  \n",
        "\n",
        "* ‚ùå Not multi-class  \n",
        "\n",
        "2. How logistic regression is extended to multi-class  \n",
        "There are two main strategies:  \n",
        "\n",
        "3. One-vs-Rest (OvR / OvA)  \n",
        "Idea (simple)  \n",
        "If you have K classes, train K binary models.  \n",
        "Each model answers:  \n",
        "‚ÄúIs this class X or not?‚Äù  \n",
        "Example: 3 classes (A, B, C)  \n",
        "You train:  \n",
        "\n",
        "* Model 1: A vs (B, C)  \n",
        "\n",
        "* Model 2: B vs (A, C)  \n",
        "\n",
        "* Model 3: C vs (A, B)  \n",
        "\n",
        "Each model outputs a probability.  \n",
        "You choose:  \n",
        "\n",
        "* The class with the highest probability  \n",
        "\n",
        "Properties  \n",
        "\n",
        "* Uses sigmoid  \n",
        "\n",
        "* Simple  \n",
        "\n",
        "* Works well in practice  \n",
        "\n",
        "* Default in many libraries  \n",
        "\n",
        "In scikit-learn  \n",
        "\n",
        "```python\n",
        "LogisticRegression(multi_class=\"ovr\")\n",
        "```\n",
        "\n",
        "4. Multinomial (Softmax Logistic Regression)  \n",
        "Idea (simple)  \n",
        "\n",
        "* Train one single model  \n",
        "\n",
        "* Predicts probabilities for all classes at once  \n",
        "\n",
        "* Uses softmax, not sigmoid  \n",
        "\n",
        "Softmax function  \n",
        "$$\n",
        "P(y=k \\mid X) = \\frac{e^{z_k}}{\\sum_{j=1}^{K} e^{z_j}}\n",
        "$$  \n",
        "Outputs:  \n",
        "\n",
        "* A probability for each class  \n",
        "\n",
        "* All probabilities sum to 1  \n",
        "\n",
        "Properties  \n",
        "\n",
        "* More mathematically correct  \n",
        "\n",
        "* Captures competition between classes  \n",
        "\n",
        "* Often performs better  \n",
        "\n",
        "* Slightly more expensive  \n",
        "\n",
        "In scikit-learn  \n",
        "\n",
        "```python\n",
        "LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\")\n",
        "```\n",
        "\n",
        "5. Comparison (easy table)  \n",
        "\n",
        "| Aspect              | One-vs-Rest | Multinomial |  \n",
        "|---------------------|-------------|-------------|  \n",
        "| Number of models    | K           | 1           |  \n",
        "| Probability function| Sigmoid     | Softmax     |  \n",
        "| Class interaction   | ‚ùå No       | ‚úÖ Yes      |  \n",
        "| Mathematical elegance| Medium    | High        |  \n",
        "| Default in many tools| ‚úÖ         | ‚ùå          |  \n",
        "\n",
        "6. When should you use which?  \n",
        "Use One-vs-Rest when:  \n",
        "\n",
        "* Dataset is small  \n",
        "\n",
        "* Classes are well separated  \n",
        "\n",
        "* You want simplicity  \n",
        "\n",
        "Use Multinomial when:  \n",
        "\n",
        "* Classes overlap  \n",
        "\n",
        "* You want better probability estimates  \n",
        "\n",
        "* You want theoretically correct multi-class modeling  \n",
        "\n",
        "7. Simple intuition  \n",
        "\n",
        "* Binary logistic regression ‚Üí ‚ÄúYes or No?‚Äù  \n",
        "\n",
        "* One-vs-Rest ‚Üí ‚ÄúWhich Yes is strongest?‚Äù  \n",
        "\n",
        "* Multinomial logistic regression ‚Üí ‚ÄúWhich class is most likely overall?‚Äù  \n",
        "\n",
        "8. Final one-line answer  \n",
        "Logistic regression can be used for multi-class classification by using One-vs-Rest or Multinomial (Softmax) extensions.  \n",
        "If you want, I can show:  \n",
        "\n",
        "* A full multi-class code example  \n",
        "\n",
        "* A visual probability explanation  \n",
        "\n",
        "* Comparison with Softmax in neural networks  \n",
        "\n",
        "Just tell me.  \n",
        "\n",
        "### Mathematical Intuition with Example and Code\n",
        "\n",
        "One-vs-Rest (OvR) or One-vs-All (OvA): In this strategy, you train multiple binary classifiers, each representing one class against the rest. For k classes, you would train k separate binary Logistic Regression classifiers. During prediction, each classifier outputs a probability, and the class with the highest probability is chosen as the predicted class. This method is straightforward to implement and works well when the number of classes is not too large. Multinomial Logistic Regression (Softmax Regression): Unlike the One-vs-Rest approach, Multinomial Logistic Regression directly extends the binary Logistic Regression to handle multiple classes. It uses the softmax activation function to calculate probabilities for each class. The softmax function converts raw scores (logits) into probabilities, ensuring that the sum of probabilities across all classes equals 1. This method considers all classes simultaneously during training and prediction, prov give mathematic instution with a problem of example and write code also with data set with show output  \n",
        "Below is the mathematical intuition for OvR (One-vs-Rest) and Multinomial (Softmax) Logistic Regression, with a worked example, and complete Python code using a real dataset (Iris) plus actual output.  \n",
        "\n",
        "1) Problem setup (example)  \n",
        "Assume we want to classify a flower into 3 classes:  \n",
        "\n",
        "* Class 0: setosa  \n",
        "\n",
        "* Class 1: versicolor  \n",
        "\n",
        "* Class 2: virginica  \n",
        "\n",
        "Input features $x$ (for example) could be:  \n",
        "$$\n",
        "x = [\\text{sepal length}, \\text{sepal width}, \\text{petal length}, \\text{petal width}]\n",
        "$$  \n",
        "\n",
        "2) One-vs-Rest (OvR / OvA): Mathematical intuition  \n",
        "What you train  \n",
        "For $K$ classes, you train $K$ separate binary logistic regression models.  \n",
        "For class $k$, you create labels:  \n",
        "$$\n",
        "y^{(k)} = \\begin{cases}\n",
        "1 & \\text{if original class is } k \\\\\n",
        "0 & \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$  \n",
        "Then each model learns:  \n",
        "$$\n",
        "p_k(x) = P(y^{(k)}=1 \\mid x) = \\sigma(z_k)\n",
        "$$  \n",
        "where  \n",
        "$$\n",
        "z_k = w_k^T x + b_k\n",
        "$$  \n",
        "and the sigmoid function:  \n",
        "$$\n",
        "\\sigma(z)=\\frac{1}{1+e^{-z}}\n",
        "$$  \n",
        "Prediction rule (decision)  \n",
        "Compute all $K$ probabilities and pick the maximum:  \n",
        "$$\n",
        "\\hat{y} = \\arg\\max_k p_k(x)\n",
        "$$  \n",
        "Important note  \n",
        "In OvR, the $p_k(x)$ values are produced by separate models, so they may not sum to 1 perfectly (they are not forced to compete jointly).  \n",
        "\n",
        "3) Multinomial (Softmax): Mathematical intuition  \n",
        "What you train  \n",
        "You train one single model with $K$ weight vectors (one per class). Compute logits:  \n",
        "$$\n",
        "z_k = w_k^T x + b_k \\quad \\text{for } k=1..K\n",
        "$$  \n",
        "Then convert logits to probabilities using softmax:  \n",
        "$$\n",
        "P(y=k \\mid x)=\\frac{e^{z_k}}{\\sum_{j=1}^{K} e^{z_j}}\n",
        "$$  \n",
        "Prediction rule (decision)  \n",
        "$$\n",
        "\\hat{y} = \\arg\\max_k P(y=k \\mid x)\n",
        "$$  \n",
        "Key idea  \n",
        "Softmax forces all classes to compete because the denominator includes every class. Also, the probabilities always sum to 1.  \n",
        "\n",
        "4) Mini numeric example (intuition)  \n",
        "Suppose your model outputs logits for 3 classes:  \n",
        "$$\n",
        "z = [2,\\ 1,\\ 0]\n",
        "$$  \n",
        "Softmax probabilities  \n",
        "$$\n",
        "P_0=\\frac{e^2}{e^2+e^1+e^0},\\ P_1=\\frac{e^1}{e^2+e^1+e^0},\\ P_2=\\frac{e^0}{e^2+e^1+e^0}\n",
        "$$  \n",
        "Since $e^2$ is largest, class 0 gets highest probability.  \n",
        "Decision: choose class 0.  \n",
        "\n",
        "5) Complete code (OvR vs Multinomial) with dataset + output  \n",
        "I used the Iris dataset (3 classes) and trained both approaches.  \n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, log_loss\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# Dataset: Iris (3 classes)\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "class_names = iris.target_names\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, stratify=y, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# OvR (One-vs-Rest)\n",
        "ovr_model = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(\n",
        "        multi_class=\"ovr\",\n",
        "        solver=\"liblinear\",\n",
        "        C=1.0,\n",
        "        max_iter=2000,\n",
        "        random_state=RANDOM_STATE\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Multinomial (Softmax)\n",
        "multi_model = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(\n",
        "        multi_class=\"multinomial\",\n",
        "        solver=\"lbfgs\",\n",
        "        C=1.0,\n",
        "        max_iter=2000,\n",
        "        random_state=RANDOM_STATE\n",
        "    ))\n",
        "])\n",
        "\n",
        "ovr_model.fit(X_train, y_train)\n",
        "multi_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions and probabilities\n",
        "y_pred_ovr = ovr_model.predict(X_test)\n",
        "p_ovr = ovr_model.predict_proba(X_test)\n",
        "\n",
        "y_pred_multi = multi_model.predict(X_test)\n",
        "p_multi = multi_model.predict_proba(X_test)\n",
        "\n",
        "# Metrics\n",
        "print(\"OvR Accuracy:\", accuracy_score(y_test, y_pred_ovr))\n",
        "print(\"OvR LogLoss :\", log_loss(y_test, p_ovr))\n",
        "print(\"OvR Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_ovr))\n",
        "print(\"\\nOvR Report:\\n\", classification_report(y_test, y_pred_ovr, target_names=class_names, digits=3))\n",
        "\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "print(\"Softmax Accuracy:\", accuracy_score(y_test, y_pred_multi))\n",
        "print(\"Softmax LogLoss :\", log_loss(y_test, p_multi))\n",
        "print(\"Softmax Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_multi))\n",
        "print(\"\\nSoftmax Report:\\n\", classification_report(y_test, y_pred_multi, target_names=class_names, digits=3))\n",
        "```\n",
        "\n",
        "Actual output from running this code  \n",
        "Summary (accuracy + log loss):  \n",
        "\n",
        "* OvR accuracy: 0.7632  \n",
        "\n",
        "* OvR log loss: 0.4592  \n",
        "\n",
        "* Softmax accuracy: 0.9211  \n",
        "\n",
        "* Softmax log loss: 0.2090  \n",
        "\n",
        "Confusion matrices:  \n",
        "\n",
        "* OvR:  \n",
        "\n",
        "  ```\n",
        "  [[11  1  0]\n",
        "   [ 0  7  6]\n",
        "   [ 0  2 11]]\n",
        "  ```\n",
        "\n",
        "* Softmax:  \n",
        "\n",
        "  ```\n",
        "  [[12  0  0]\n",
        "   [ 0 12  1]\n",
        "   [ 0  2 11]]\n",
        "  ```\n",
        "\n",
        "Interpretation:  \n",
        "\n",
        "* Softmax performed better here, especially distinguishing versicolor vs virginica (the tricky pair).  \n",
        "\n",
        "6) When should you use OvR vs Softmax?  \n",
        "Prefer OvR when:  \n",
        "\n",
        "* You want simple training  \n",
        "\n",
        "* Very large number of classes but you want independent binary models  \n",
        "\n",
        "* You need compatibility with certain solvers/constraints  \n",
        "\n",
        "Prefer Softmax (Multinomial) when:  \n",
        "\n",
        "* Classes overlap and compete (common)  \n",
        "\n",
        "* You want better calibrated probabilities  \n",
        "\n",
        "* You want ‚Äútrue‚Äù multi-class logistic regression  \n",
        "\n",
        "If you want, I can also show (with code) how to manually compute softmax probabilities from logits, so you can see the math numerically step-by-step for a single sample.  \n",
        "\n",
        "## Solvers in Logistic Regression\n",
        "\n",
        "solvers  \n",
        "what is this  \n",
        "In very simple language, a solver is:  \n",
        "The algorithm (method) that the computer uses to learn the model‚Äôs weights from data.  \n",
        "Logistic regression has a formula, but there is no direct closed-form solution.  \n",
        "So the model must iteratively search for the best weights that minimize the loss.  \n",
        "That searching process is done by a solver.  \n",
        "\n",
        "1) Why do we need a solver?  \n",
        "Logistic Regression tries to minimize log loss:  \n",
        "$$\n",
        "\\text{Loss} = -\\sum \\big[y \\log(p) + (1-y)\\log(1-p)\\big]\n",
        "$$  \n",
        "There is no single equation to solve this directly.  \n",
        "So the solver:  \n",
        "\n",
        "* starts with random weights  \n",
        "\n",
        "* repeatedly improves them  \n",
        "\n",
        "* stops when improvement is small  \n",
        "\n",
        "2) Common solvers in Logistic Regression (easy explanation)  \n",
        "1. liblinear  \n",
        "\n",
        "* Works by solving many small optimization problems  \n",
        "\n",
        "* Very stable and reliable  \n",
        "\n",
        "* Best for small to medium datasets  \n",
        "\n",
        "* Supports:  \n",
        "\n",
        "  * Binary classification  \n",
        "\n",
        "  * One-vs-Rest  \n",
        "\n",
        "  * L1 and L2 regularization  \n",
        "\n",
        "Use when:  \n",
        "‚ÄúI want something simple and dependable.‚Äù  \n",
        "\n",
        "```python\n",
        "LogisticRegression(solver=\"liblinear\")\n",
        "```\n",
        "\n",
        "2. lbfgs  \n",
        "\n",
        "* Uses gradient information efficiently  \n",
        "\n",
        "* Default solver in scikit-learn  \n",
        "\n",
        "* Fast for medium to large datasets  \n",
        "\n",
        "* Required for multinomial (softmax)  \n",
        "\n",
        "Supports:  \n",
        "\n",
        "* L2 regularization  \n",
        "\n",
        "* Multiclass softmax  \n",
        "\n",
        "```python\n",
        "LogisticRegression(solver=\"lbfgs\", multi_class=\"multinomial\")\n",
        "```\n",
        "\n",
        "3. saga  \n",
        "\n",
        "* Handles very large datasets  \n",
        "\n",
        "* Supports:  \n",
        "\n",
        "  * L1  \n",
        "\n",
        "  * L2  \n",
        "\n",
        "  * ElasticNet  \n",
        "\n",
        "  * Multinomial  \n",
        "\n",
        "Best when:  \n",
        "‚ÄúI want feature selection or elastic-net regularization.‚Äù  \n",
        "\n",
        "```python\n",
        "LogisticRegression(solver=\"saga\", penalty=\"elasticnet\", l1_ratio=0.5)\n",
        "```\n",
        "\n",
        "4. sag  \n",
        "\n",
        "* Similar to saga but no L1  \n",
        "\n",
        "* Faster on large datasets  \n",
        "\n",
        "* Less commonly used  \n",
        "\n",
        "3) Which solver should you use? (Simple rule)  \n",
        "\n",
        "| Situation              | Solver    |  \n",
        "|------------------------|-----------|  \n",
        "| Binary classification  | liblinear |  \n",
        "| Multiclass (softmax)   | lbfgs     |  \n",
        "| Very large data        | saga      |  \n",
        "| L1 regularization      | liblinear or saga |  \n",
        "| ElasticNet             | saga only |  \n",
        "\n",
        "4) Why solver choice matters  \n",
        "Different solvers:  \n",
        "\n",
        "* converge at different speeds  \n",
        "\n",
        "* support different penalties  \n",
        "\n",
        "* support different multiclass strategies  \n",
        "\n",
        "Wrong solver ‚Üí error or poor performance.  \n",
        "\n",
        "5) One-sentence summary  \n",
        "A solver is the optimization algorithm that finds the best weights for logistic regression by minimizing the loss function.  \n",
        "If you want, I can next explain:  \n",
        "\n",
        "* solvers with visual intuition  \n",
        "\n",
        "* what gradient descent is  \n",
        "\n",
        "* why some solvers don‚Äôt support softmax  \n",
        "\n",
        "* how solvers affect training time vs accuracy"
      ],
      "metadata": {
        "id": "K5ys38RX9236"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "# True labels\n",
        "y_true = np.array([1,1,1,1,0,0,0,0,0,0])\n",
        "\n",
        "# Predicted probabilities\n",
        "y_prob = np.array([0.95,0.85,0.70,0.40,0.60,0.45,0.30,0.20,0.10,0.05])\n",
        "\n",
        "# ROC values\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
        "auc = roc_auc_score(y_true, y_prob)\n",
        "\n",
        "print(\"AUC:\", auc)\n",
        "\n",
        "# Plot ROC\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr)\n",
        "plt.plot([0,1], [0,1])  # random baseline\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "Cf-pEMM9-yTJ",
        "outputId": "6659c21e-c9fa-4a48-d133-a240c2c0dc23"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 0.9166666666666667\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        ")\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# 1) Load a built-in binary classification dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target  # 0 = malignant, 1 = benign (positive class here)\n",
        "\n",
        "# 2) Split into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# 3) Pipeline: scaling + logistic regression\n",
        "model = Pipeline(\n",
        "    steps=[\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"clf\", LogisticRegression(max_iter=3000, random_state=RANDOM_STATE)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 4) Train\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5) Predict\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 6) Metrics\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_prob)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=[\"malignant(0)\", \"benign(1)\"], digits=3)\n",
        "\n",
        "print(\"BASELINE RESULTS\")\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"ROC-AUC : {auc:.4f}\")\n",
        "print(\"Confusion matrix:\\n\", cm)\n",
        "print(\"\\nClassification report:\\n\", report)\n",
        "\n",
        "# 7) ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr)\n",
        "plt.plot([0, 1], [0, 1])  # random baseline\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve (Baseline Logistic Regression)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "q1KIv0t0_UTB",
        "outputId": "456e1eac-e53c-4b61-fd39-060b577e8d1f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BASELINE RESULTS\n",
            "Accuracy: 0.9825\n",
            "ROC-AUC : 0.9954\n",
            "Confusion matrix:\n",
            " [[41  1]\n",
            " [ 1 71]]\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "malignant(0)      0.976     0.976     0.976        42\n",
            "   benign(1)      0.986     0.986     0.986        72\n",
            "\n",
            "    accuracy                          0.982       114\n",
            "   macro avg      0.981     0.981     0.981       114\n",
            "weighted avg      0.982     0.982     0.982       114\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "\n",
        "param_grid = {\n",
        "    \"clf__solver\": [\"liblinear\"],      # simple, robust solver\n",
        "    \"clf__penalty\": [\"l2\"],            # L2 regularization\n",
        "    \"clf__C\": [0.1, 1, 10],            # regularization strength\n",
        "    \"clf__class_weight\": [None, \"balanced\"],  # handle imbalance\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"roc_auc\",   # optimize for ranking quality\n",
        "    cv=cv,\n",
        "    n_jobs=1\n",
        ")\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "# Evaluate tuned model\n",
        "y_pred_t = best_model.predict(X_test)\n",
        "y_prob_t = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "acc_t = accuracy_score(y_test, y_pred_t)\n",
        "auc_t = roc_auc_score(y_test, y_prob_t)\n",
        "cm_t = confusion_matrix(y_test, y_pred_t)\n",
        "\n",
        "print(\"TUNED RESULTS (GridSearchCV)\")\n",
        "print(\"Best params:\", grid.best_params_)\n",
        "print(f\"Best CV ROC-AUC: {grid.best_score_:.4f}\")\n",
        "print(f\"Test Accuracy: {acc_t:.4f}\")\n",
        "print(f\"Test ROC-AUC : {auc_t:.4f}\")\n",
        "print(\"Confusion matrix:\\n\", cm_t)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtcN1fsZ_ZSR",
        "outputId": "1d90235f-86a4-4222-99f8-f3fbe483b3a7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TUNED RESULTS (GridSearchCV)\n",
            "Best params: {'clf__C': 1, 'clf__class_weight': None, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}\n",
            "Best CV ROC-AUC: 0.9954\n",
            "Test Accuracy: 0.9825\n",
            "Test ROC-AUC : 0.9957\n",
            "Confusion matrix:\n",
            " [[41  1]\n",
            " [ 1 71]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, log_loss\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# Dataset: Iris (3 classes)\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "class_names = iris.target_names\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, stratify=y, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# OvR (One-vs-Rest)\n",
        "ovr_model = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(\n",
        "        multi_class=\"ovr\",\n",
        "        solver=\"liblinear\",\n",
        "        C=1.0,\n",
        "        max_iter=2000,\n",
        "        random_state=RANDOM_STATE\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Multinomial (Softmax)\n",
        "multi_model = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(\n",
        "        multi_class=\"multinomial\",\n",
        "        solver=\"lbfgs\",\n",
        "        C=1.0,\n",
        "        max_iter=2000,\n",
        "        random_state=RANDOM_STATE\n",
        "    ))\n",
        "])\n",
        "\n",
        "ovr_model.fit(X_train, y_train)\n",
        "multi_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions and probabilities\n",
        "y_pred_ovr = ovr_model.predict(X_test)\n",
        "p_ovr = ovr_model.predict_proba(X_test)\n",
        "\n",
        "y_pred_multi = multi_model.predict(X_test)\n",
        "p_multi = multi_model.predict_proba(X_test)\n",
        "\n",
        "# Metrics\n",
        "print(\"OvR Accuracy:\", accuracy_score(y_test, y_pred_ovr))\n",
        "print(\"OvR LogLoss :\", log_loss(y_test, p_ovr))\n",
        "print(\"OvR Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_ovr))\n",
        "print(\"\\nOvR Report:\\n\", classification_report(y_test, y_pred_ovr, target_names=class_names, digits=3))\n",
        "\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "print(\"Softmax Accuracy:\", accuracy_score(y_test, y_pred_multi))\n",
        "print(\"Softmax LogLoss :\", log_loss(y_test, p_multi))\n",
        "print(\"Softmax Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_multi))\n",
        "print(\"\\nSoftmax Report:\\n\", classification_report(y_test, y_pred_multi, target_names=class_names, digits=3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnOOx69z_he5",
        "outputId": "e68b12b9-75d1-4761-de87-c91712374564"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OvR Accuracy: 0.7631578947368421\n",
            "OvR LogLoss : 0.4592366669613188\n",
            "OvR Confusion Matrix:\n",
            " [[11  1  0]\n",
            " [ 0  7  6]\n",
            " [ 0  2 11]]\n",
            "\n",
            "OvR Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      setosa      1.000     0.917     0.957        12\n",
            "  versicolor      0.700     0.538     0.609        13\n",
            "   virginica      0.647     0.846     0.733        13\n",
            "\n",
            "    accuracy                          0.763        38\n",
            "   macro avg      0.782     0.767     0.766        38\n",
            "weighted avg      0.777     0.763     0.761        38\n",
            "\n",
            "\n",
            "============================================================\n",
            "\n",
            "Softmax Accuracy: 0.9210526315789473\n",
            "Softmax LogLoss : 0.20896788754144638\n",
            "Softmax Confusion Matrix:\n",
            " [[12  0  0]\n",
            " [ 0 12  1]\n",
            " [ 0  2 11]]\n",
            "\n",
            "Softmax Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      setosa      1.000     1.000     1.000        12\n",
            "  versicolor      0.857     0.923     0.889        13\n",
            "   virginica      0.917     0.846     0.880        13\n",
            "\n",
            "    accuracy                          0.921        38\n",
            "   macro avg      0.925     0.923     0.923        38\n",
            "weighted avg      0.923     0.921     0.921        38\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}